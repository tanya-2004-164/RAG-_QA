# -*- coding: utf-8 -*-
"""Untitled12.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SMICB8TXls04wGtPZv12Y2q-lnl5y3Kg
"""

!pip install openai==0.27.8

import google.generativeai as genai

genai.configure(api_key="AIzaSyBCiF7kzYFxWuQJ9P0oD2DcgYkEn6yDcuY")
model = genai.GenerativeModel("gemini-1.5-flash")

from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np

# Initialize GPT API
genai.configure(api_key="AIzaSyBCiF7kzYFxWuQJ9P0oD2DcgYkEn6yDcuY")
model = genai.GenerativeModel("gemini-1.5-flash")

# Initialize Embedding Model (like OpenAI or SentenceTransformers)
model = SentenceTransformer('all-MiniLM-L6-v2')

# Step 1: Prepare Documents
documents = {
    "doc1": "This is a document about business strategies.",
    "doc2": "This document explains product pricing models.",
    "doc3": "Details about customer retention techniques."
}

# Step 2: Generate Embeddings
doc_embeddings = {key: model.encode(value) for key, value in documents.items()}

# Step 3: Query and Find Relevant Document
def retrieve_relevant_context(query, embeddings):
    query_embedding = model.encode(query)
    scores = {key: cosine_similarity([query_embedding], [value])[0][0] for key, value in embeddings.items()}
    sorted_docs = sorted(scores.items(), key=lambda x: x[1], reverse=True)
    return sorted_docs[0][0], sorted_docs[0][1]

# Example Query
query = "How to retain customers?"
doc_id, similarity = retrieve_relevant_context(query, doc_embeddings)
print(f"Relevant Document: {documents[doc_id]} (Similarity: {similarity:.2f})")

# Step 4: Use GPT-4 for Augmented Answer
response = genai.configure(
    model="gemini-1.5-flash",
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": f"Based on this context: {documents[doc_id]}, answer this query: {query}"}
    ]
)

print(response["choices"][0]["message"]["content"])

